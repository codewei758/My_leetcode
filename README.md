本篇文章是我在2019年8月阅读完论文“[Wu, Zonghan , et al. "A Comprehensive Survey on Graph Neural Networks." (2019).](https://arxiv.org/abs/1901.00596)“”后的翻译与笔记，写下这篇文章后不久便意外地转换了研究方向，如今已不再研究深度学习，所以文中难免有纰漏之处，欢迎发现的知友在评论中指出并给予宝贵的修改意见。

目录

一、什么是图神经网络

二、有哪些图神经网络

三、图神经网络的应用

------

## **一、什么是图神经网络？**

在过去的几年中，神经网络的兴起与应用成功推动了模式识别和数据挖掘的研究。许多曾经严重依赖于手工提取特征的机器学习任务（如目标检测、机器翻译和语音识别），如今都已被各种端到端的深度学习范式（例如卷积神经网络（CNN）、长短期记忆（LSTM）和自动编码器）彻底改变了。曾有学者将本次人工智能浪潮的兴起归因于三个条件，分别是：

- 计算资源的快速发展（如GPU）
- 大量训练数据的可用性
- 深度学习从欧氏空间数据中提取潜在特征的有效性

尽管传统的深度学习方法被应用在提取欧氏空间数据的特征方面取得了巨大的成功，但许多实际应用场景中的数据是从非欧式空间生成的，传统的深度学习方法在处理非欧式空间数据上的表现却仍难以使人满意。例如，在电子商务中，一个基于图（Graph）的学习系统能够利用用户和产品之间的交互来做出非常准确的推荐，但图的复杂性使得现有的深度学习算法在处理时面临着巨大的挑战。这是因为图是不规则的，每个图都有一个大小可变的无序节点，图中的每个节点都有不同数量的相邻节点，导致一些重要的操作（例如卷积）在图像（Image）上很容易计算，但不再适合直接用于图。此外，现有深度学习算法的一个核心假设是数据样本之间彼此独立。然而，对于图来说，情况并非如此，图中的每个数据样本（节点）都会有边与图中其他实数据样本（节点）相关，这些信息可用于捕获实例之间的相互依赖关系。

近年来，人们对深度学习方法在图上的扩展越来越感兴趣。在多方因素的成功推动下，研究人员借鉴了卷积网络、循环网络和深度自动编码器的思想，定义和设计了用于处理图数据的神经网络结构，由此一个新的研究热点——“**图神经网络（Graph Neural Networks，GNN）**”应运而生，本篇文章主要对图神经网络的研究现状进行简单的概述。

需要注意的是，图神经网络的研究与图嵌入（对图嵌入不了解的读者可以参考我的这篇文章《[图嵌入综述](https://zhuanlan.zhihu.com/p/62629465)》）或网络嵌入密切相关，图嵌入或网络嵌入是数据挖掘和机器学习界日益关注的另一个课题。图嵌入旨在通过保留图的网络拓扑结构和节点内容信息，将图中顶点表示为低维向量，以便使用简单的机器学习算法（例如，支持向量机分类）进行处理。许多图嵌入算法通常是无监督的算法，它们可以大致可以划分为三个类别，即矩阵分解、随机游走和深度学习方法。同时图嵌入的深度学习方法也属于图神经网络，包括基于图自动编码器的算法（如DNGR和SDNE）和无监督训练的图卷积神经网络（如GraphSage）。下图描述了图嵌入和图神经网络在本文中的区别。

![](https://raw.githubusercontent.com/codewei758/My_pic/master/202211141624133.png)

## **二、有哪些图神经网络？**

在本文中，我们将图神经网络划分为五大类别，分别是：图卷积网络（Graph Convolution Networks，GCN）、 图注意力网络（Graph Attention Networks）、图自编码器（ Graph Autoencoders）、图生成网络（ Graph Generative Networks） 和图时空网络（Graph Spatial-temporal Networks）。

**符号定义**

<img src="https://raw.githubusercontent.com/codewei758/My_pic/master/202211141637538.png" style="zoom:50%;" />

**1、图卷积网络（Graph Convolution Networks，ConvGNNs）**

图卷积网络将卷积运算从传统数据（例如图像）推广到图数据。其核心思想是学习一个函数映射 $f(·)$ ，通过该映射图中的节点 $v_i$ 可以聚合它自己的特征 $x_i$ 与它的邻居特征 $x_j\quad\left(j \in N\left(v_i\right)\right)$来生成节点 $v_i$ 的新表示。图卷积网络是许多复杂图神经网络模型的基础，包括基于自动编码器的模型、生成模型和时空网络等。下图直观地展示了图神经网络学习节点表示的步骤。

![一种具有多图卷积层的卷积神经网络。图卷积层通过聚合相邻节点的特征信息来封装每个节点的隐藏表示。特征聚合后，对产生的输出进行非线性变换。通过叠加多层，每个节点的最终隐藏表示从进一步的邻域接收消息。](https://raw.githubusercontent.com/codewei758/My_pic/master/202211141650484.png)

GCN方法又可以分为两大类，基于谱（spectral-based）和基于空间（spatial-based）。基于谱的方法从图信号处理的角度引入滤波器来定义图卷积，其中图卷积操作被解释为从图信号中去除噪声。基于空间的方法将图卷积表示为从邻域聚合特征信息，当图卷积网络的算法在节点层次运行时，图池化模块可以与图卷积层交错，将图粗化为高级子结构。如下图所示，这种架构设计可用于提取图的各级表示和执行图分类任务。
